{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prerequisites\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "bs = 100\n",
    "# MNIST Dataset\n",
    "train_dataset = datasets.MNIST(root='./mnist_data/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./mnist_data/', train=False, transform=transforms.ToTensor(), download=False)\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std) # create a tensor (same shape with input) ,each element is sampled from normal Guaissian.\n",
    "        # std here as input only influence the shape of eps, rather than define guassian 's sigma!!! 在下面测试了\n",
    "        return eps.mul(std).add_(mu) # return z sample   # 从 标准高斯 映射到 普通高斯。\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_dev = 10000000000.0\n",
    "# input_tensor = torch.tensor(std_dev)\n",
    "\n",
    "# # 使用 torch.randn_like 创建一个具有相同形状的随机张量，但标准差为 input_tensor 的值\n",
    "# random_tensor = torch.randn_like(input_tensor)\n",
    "\n",
    "# print(random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc31): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc32): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (fc4): Linear(in_features=2, out_features=256, bias=True)\n",
       "  (fc5): Linear(in_features=256, out_features=512, bias=True)\n",
       "  (fc6): Linear(in_features=512, out_features=784, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')       # 二值分布下 重构损失算出来正比于二进制交叉熵\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())               # 两高斯分布间的KL 散度，有公式。 .exp() 即以e为base，log_var 为指数，结果就是 var！\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()     \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 543.045859\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 190.692734\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 171.830957\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 173.555645\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 176.866855\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 158.913096\n",
      "====> Epoch: 1 Average loss: 180.6820\n",
      "====> Test set loss: 163.8706\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 163.061055\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 168.777891\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 164.829199\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 160.373047\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 154.356309\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 161.251777\n",
      "====> Epoch: 2 Average loss: 159.5319\n",
      "====> Test set loss: 155.8455\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 155.014248\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 146.828193\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 149.715059\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 154.014395\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 155.388447\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 150.604893\n",
      "====> Epoch: 3 Average loss: 153.9632\n",
      "====> Test set loss: 151.4217\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 148.589189\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 153.756621\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 148.822520\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 159.020957\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 166.081133\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 142.181777\n",
      "====> Epoch: 4 Average loss: 150.5528\n",
      "====> Test set loss: 148.8612\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 145.362129\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 154.429912\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 151.272188\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 151.898164\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 139.490645\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 145.994834\n",
      "====> Epoch: 5 Average loss: 148.5137\n",
      "====> Test set loss: 147.5161\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 151.172305\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 146.314805\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 141.377256\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 146.539648\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 156.795342\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 144.111807\n",
      "====> Epoch: 6 Average loss: 146.8862\n",
      "====> Test set loss: 146.4057\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 146.440557\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 143.860488\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 143.028955\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 141.092246\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 149.249307\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 145.936006\n",
      "====> Epoch: 7 Average loss: 145.4656\n",
      "====> Test set loss: 145.0687\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 144.828652\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 145.604980\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 149.614639\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 142.799570\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 143.955283\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 140.861270\n",
      "====> Epoch: 8 Average loss: 144.4192\n",
      "====> Test set loss: 144.6671\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 151.293311\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 147.025527\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 136.344678\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 141.099336\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 149.229277\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 142.425537\n",
      "====> Epoch: 9 Average loss: 143.3940\n",
      "====> Test set loss: 143.0478\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 140.511133\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 137.068799\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 140.125332\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 144.672725\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 150.026797\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 139.239004\n",
      "====> Epoch: 10 Average loss: 142.5283\n",
      "====> Test set loss: 142.6283\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 146.477969\n",
      "Train Epoch: 11 [10000/60000 (17%)]\tLoss: 138.261709\n",
      "Train Epoch: 11 [20000/60000 (33%)]\tLoss: 144.858242\n",
      "Train Epoch: 11 [30000/60000 (50%)]\tLoss: 142.794150\n",
      "Train Epoch: 11 [40000/60000 (67%)]\tLoss: 143.227949\n",
      "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 146.153604\n",
      "====> Epoch: 11 Average loss: 141.8678\n",
      "====> Test set loss: 142.7000\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 141.697812\n",
      "Train Epoch: 12 [10000/60000 (17%)]\tLoss: 136.388145\n",
      "Train Epoch: 12 [20000/60000 (33%)]\tLoss: 142.005020\n",
      "Train Epoch: 12 [30000/60000 (50%)]\tLoss: 139.792314\n",
      "Train Epoch: 12 [40000/60000 (67%)]\tLoss: 137.403623\n",
      "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 138.288213\n",
      "====> Epoch: 12 Average loss: 141.3136\n",
      "====> Test set loss: 141.8943\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 136.457109\n",
      "Train Epoch: 13 [10000/60000 (17%)]\tLoss: 140.591602\n",
      "Train Epoch: 13 [20000/60000 (33%)]\tLoss: 138.934512\n",
      "Train Epoch: 13 [30000/60000 (50%)]\tLoss: 137.668672\n",
      "Train Epoch: 13 [40000/60000 (67%)]\tLoss: 137.461328\n",
      "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 133.393223\n",
      "====> Epoch: 13 Average loss: 140.6734\n",
      "====> Test set loss: 141.7055\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 141.868340\n",
      "Train Epoch: 14 [10000/60000 (17%)]\tLoss: 146.863594\n",
      "Train Epoch: 14 [20000/60000 (33%)]\tLoss: 137.405557\n",
      "Train Epoch: 14 [30000/60000 (50%)]\tLoss: 138.460645\n",
      "Train Epoch: 14 [40000/60000 (67%)]\tLoss: 133.396709\n",
      "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 139.447363\n",
      "====> Epoch: 14 Average loss: 140.1327\n",
      "====> Test set loss: 140.4413\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 141.812803\n",
      "Train Epoch: 15 [10000/60000 (17%)]\tLoss: 145.226660\n",
      "Train Epoch: 15 [20000/60000 (33%)]\tLoss: 143.462900\n",
      "Train Epoch: 15 [30000/60000 (50%)]\tLoss: 132.441045\n",
      "Train Epoch: 15 [40000/60000 (67%)]\tLoss: 148.344570\n",
      "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 136.386016\n",
      "====> Epoch: 15 Average loss: 139.7571\n",
      "====> Test set loss: 141.0354\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 136.072090\n",
      "Train Epoch: 16 [10000/60000 (17%)]\tLoss: 139.653525\n",
      "Train Epoch: 16 [20000/60000 (33%)]\tLoss: 144.404277\n",
      "Train Epoch: 16 [30000/60000 (50%)]\tLoss: 137.255303\n",
      "Train Epoch: 16 [40000/60000 (67%)]\tLoss: 138.944902\n",
      "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 147.175830\n",
      "====> Epoch: 16 Average loss: 139.6033\n",
      "====> Test set loss: 140.3538\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 143.082119\n",
      "Train Epoch: 17 [10000/60000 (17%)]\tLoss: 133.479658\n",
      "Train Epoch: 17 [20000/60000 (33%)]\tLoss: 132.938047\n",
      "Train Epoch: 17 [30000/60000 (50%)]\tLoss: 141.674746\n",
      "Train Epoch: 17 [40000/60000 (67%)]\tLoss: 140.569844\n",
      "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 142.736162\n",
      "====> Epoch: 17 Average loss: 138.9387\n",
      "====> Test set loss: 140.0190\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 133.113818\n",
      "Train Epoch: 18 [10000/60000 (17%)]\tLoss: 143.983525\n",
      "Train Epoch: 18 [20000/60000 (33%)]\tLoss: 131.539336\n",
      "Train Epoch: 18 [30000/60000 (50%)]\tLoss: 141.769258\n",
      "Train Epoch: 18 [40000/60000 (67%)]\tLoss: 139.118164\n",
      "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 147.262900\n",
      "====> Epoch: 18 Average loss: 138.6111\n",
      "====> Test set loss: 139.5185\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 130.187373\n",
      "Train Epoch: 19 [10000/60000 (17%)]\tLoss: 147.274336\n",
      "Train Epoch: 19 [20000/60000 (33%)]\tLoss: 132.461387\n",
      "Train Epoch: 19 [30000/60000 (50%)]\tLoss: 137.382383\n",
      "Train Epoch: 19 [40000/60000 (67%)]\tLoss: 131.456436\n",
      "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 133.832812\n",
      "====> Epoch: 19 Average loss: 138.4733\n",
      "====> Test set loss: 139.8272\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 136.373281\n",
      "Train Epoch: 20 [10000/60000 (17%)]\tLoss: 138.377676\n",
      "Train Epoch: 20 [20000/60000 (33%)]\tLoss: 139.840908\n",
      "Train Epoch: 20 [30000/60000 (50%)]\tLoss: 140.546523\n",
      "Train Epoch: 20 [40000/60000 (67%)]\tLoss: 138.932324\n",
      "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 140.205820\n",
      "====> Epoch: 20 Average loss: 138.3444\n",
      "====> Test set loss: 139.5667\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 134.569248\n",
      "Train Epoch: 21 [10000/60000 (17%)]\tLoss: 139.391719\n",
      "Train Epoch: 21 [20000/60000 (33%)]\tLoss: 137.323457\n",
      "Train Epoch: 21 [30000/60000 (50%)]\tLoss: 134.486514\n",
      "Train Epoch: 21 [40000/60000 (67%)]\tLoss: 136.113799\n",
      "Train Epoch: 21 [50000/60000 (83%)]\tLoss: 142.640957\n",
      "====> Epoch: 21 Average loss: 138.0232\n",
      "====> Test set loss: 139.6301\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 135.878135\n",
      "Train Epoch: 22 [10000/60000 (17%)]\tLoss: 128.228066\n",
      "Train Epoch: 22 [20000/60000 (33%)]\tLoss: 138.063174\n",
      "Train Epoch: 22 [30000/60000 (50%)]\tLoss: 145.052236\n",
      "Train Epoch: 22 [40000/60000 (67%)]\tLoss: 133.081777\n",
      "Train Epoch: 22 [50000/60000 (83%)]\tLoss: 138.071680\n",
      "====> Epoch: 22 Average loss: 137.8332\n",
      "====> Test set loss: 139.3729\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 136.300479\n",
      "Train Epoch: 23 [10000/60000 (17%)]\tLoss: 146.804326\n",
      "Train Epoch: 23 [20000/60000 (33%)]\tLoss: 137.531934\n",
      "Train Epoch: 23 [30000/60000 (50%)]\tLoss: 135.128047\n",
      "Train Epoch: 23 [40000/60000 (67%)]\tLoss: 137.709531\n",
      "Train Epoch: 23 [50000/60000 (83%)]\tLoss: 129.503203\n",
      "====> Epoch: 23 Average loss: 137.5437\n",
      "====> Test set loss: 139.1544\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 140.567217\n",
      "Train Epoch: 24 [10000/60000 (17%)]\tLoss: 137.722383\n",
      "Train Epoch: 24 [20000/60000 (33%)]\tLoss: 132.998857\n",
      "Train Epoch: 24 [30000/60000 (50%)]\tLoss: 131.983271\n",
      "Train Epoch: 24 [40000/60000 (67%)]\tLoss: 140.033652\n",
      "Train Epoch: 24 [50000/60000 (83%)]\tLoss: 140.373389\n",
      "====> Epoch: 24 Average loss: 137.2252\n",
      "====> Test set loss: 138.7565\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 138.101279\n",
      "Train Epoch: 25 [10000/60000 (17%)]\tLoss: 144.338936\n",
      "Train Epoch: 25 [20000/60000 (33%)]\tLoss: 137.806602\n",
      "Train Epoch: 25 [30000/60000 (50%)]\tLoss: 149.577822\n",
      "Train Epoch: 25 [40000/60000 (67%)]\tLoss: 137.364248\n",
      "Train Epoch: 25 [50000/60000 (83%)]\tLoss: 138.008799\n",
      "====> Epoch: 25 Average loss: 137.0766\n",
      "====> Test set loss: 139.0615\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 143.383115\n",
      "Train Epoch: 26 [10000/60000 (17%)]\tLoss: 125.895488\n",
      "Train Epoch: 26 [20000/60000 (33%)]\tLoss: 138.356045\n",
      "Train Epoch: 26 [30000/60000 (50%)]\tLoss: 130.177070\n",
      "Train Epoch: 26 [40000/60000 (67%)]\tLoss: 136.937187\n",
      "Train Epoch: 26 [50000/60000 (83%)]\tLoss: 142.233760\n",
      "====> Epoch: 26 Average loss: 136.9194\n",
      "====> Test set loss: 139.0664\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 139.824658\n",
      "Train Epoch: 27 [10000/60000 (17%)]\tLoss: 141.068125\n",
      "Train Epoch: 27 [20000/60000 (33%)]\tLoss: 138.694492\n",
      "Train Epoch: 27 [30000/60000 (50%)]\tLoss: 147.598613\n",
      "Train Epoch: 27 [40000/60000 (67%)]\tLoss: 133.278477\n",
      "Train Epoch: 27 [50000/60000 (83%)]\tLoss: 131.872393\n",
      "====> Epoch: 27 Average loss: 136.9206\n",
      "====> Test set loss: 139.2518\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 138.433340\n",
      "Train Epoch: 28 [10000/60000 (17%)]\tLoss: 134.189424\n",
      "Train Epoch: 28 [20000/60000 (33%)]\tLoss: 150.402246\n",
      "Train Epoch: 28 [30000/60000 (50%)]\tLoss: 139.689531\n",
      "Train Epoch: 28 [40000/60000 (67%)]\tLoss: 146.788164\n",
      "Train Epoch: 28 [50000/60000 (83%)]\tLoss: 140.328594\n",
      "====> Epoch: 28 Average loss: 137.1230\n",
      "====> Test set loss: 138.7873\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 144.468252\n",
      "Train Epoch: 29 [10000/60000 (17%)]\tLoss: 144.075693\n",
      "Train Epoch: 29 [20000/60000 (33%)]\tLoss: 132.885176\n",
      "Train Epoch: 29 [30000/60000 (50%)]\tLoss: 133.438662\n",
      "Train Epoch: 29 [40000/60000 (67%)]\tLoss: 131.467822\n",
      "Train Epoch: 29 [50000/60000 (83%)]\tLoss: 140.184717\n",
      "====> Epoch: 29 Average loss: 136.5785\n",
      "====> Test set loss: 138.5619\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 130.052109\n",
      "Train Epoch: 30 [10000/60000 (17%)]\tLoss: 133.622822\n",
      "Train Epoch: 30 [20000/60000 (33%)]\tLoss: 137.465508\n",
      "Train Epoch: 30 [30000/60000 (50%)]\tLoss: 137.381211\n",
      "Train Epoch: 30 [40000/60000 (67%)]\tLoss: 135.158408\n",
      "Train Epoch: 30 [50000/60000 (83%)]\tLoss: 143.218818\n",
      "====> Epoch: 30 Average loss: 136.2645\n",
      "====> Test set loss: 138.3557\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 138.194443\n",
      "Train Epoch: 31 [10000/60000 (17%)]\tLoss: 137.896670\n",
      "Train Epoch: 31 [20000/60000 (33%)]\tLoss: 135.419199\n",
      "Train Epoch: 31 [30000/60000 (50%)]\tLoss: 127.779209\n",
      "Train Epoch: 31 [40000/60000 (67%)]\tLoss: 134.638447\n",
      "Train Epoch: 31 [50000/60000 (83%)]\tLoss: 130.680889\n",
      "====> Epoch: 31 Average loss: 136.3096\n",
      "====> Test set loss: 138.4112\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 136.818486\n",
      "Train Epoch: 32 [10000/60000 (17%)]\tLoss: 132.801543\n",
      "Train Epoch: 32 [20000/60000 (33%)]\tLoss: 138.908018\n",
      "Train Epoch: 32 [30000/60000 (50%)]\tLoss: 139.047217\n",
      "Train Epoch: 32 [40000/60000 (67%)]\tLoss: 140.420283\n",
      "Train Epoch: 32 [50000/60000 (83%)]\tLoss: 132.139111\n",
      "====> Epoch: 32 Average loss: 136.0572\n",
      "====> Test set loss: 138.1971\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 137.639824\n",
      "Train Epoch: 33 [10000/60000 (17%)]\tLoss: 133.537373\n",
      "Train Epoch: 33 [20000/60000 (33%)]\tLoss: 133.458848\n",
      "Train Epoch: 33 [30000/60000 (50%)]\tLoss: 132.182852\n",
      "Train Epoch: 33 [40000/60000 (67%)]\tLoss: 136.311914\n",
      "Train Epoch: 33 [50000/60000 (83%)]\tLoss: 137.054619\n",
      "====> Epoch: 33 Average loss: 135.9361\n",
      "====> Test set loss: 138.3819\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 134.102373\n",
      "Train Epoch: 34 [10000/60000 (17%)]\tLoss: 140.701562\n",
      "Train Epoch: 34 [20000/60000 (33%)]\tLoss: 135.674355\n",
      "Train Epoch: 34 [30000/60000 (50%)]\tLoss: 135.459326\n",
      "Train Epoch: 34 [40000/60000 (67%)]\tLoss: 140.629883\n",
      "Train Epoch: 34 [50000/60000 (83%)]\tLoss: 142.275859\n",
      "====> Epoch: 34 Average loss: 136.0867\n",
      "====> Test set loss: 138.4465\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 137.314053\n",
      "Train Epoch: 35 [10000/60000 (17%)]\tLoss: 133.887979\n",
      "Train Epoch: 35 [20000/60000 (33%)]\tLoss: 136.951748\n",
      "Train Epoch: 35 [30000/60000 (50%)]\tLoss: 129.479053\n",
      "Train Epoch: 35 [40000/60000 (67%)]\tLoss: 143.627256\n",
      "Train Epoch: 35 [50000/60000 (83%)]\tLoss: 138.742129\n",
      "====> Epoch: 35 Average loss: 135.8688\n",
      "====> Test set loss: 138.0615\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 127.198076\n",
      "Train Epoch: 36 [10000/60000 (17%)]\tLoss: 135.069473\n",
      "Train Epoch: 36 [20000/60000 (33%)]\tLoss: 135.633828\n",
      "Train Epoch: 36 [30000/60000 (50%)]\tLoss: 131.244893\n",
      "Train Epoch: 36 [40000/60000 (67%)]\tLoss: 134.618086\n",
      "Train Epoch: 36 [50000/60000 (83%)]\tLoss: 131.311992\n",
      "====> Epoch: 36 Average loss: 135.7365\n",
      "====> Test set loss: 138.2369\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 131.100586\n",
      "Train Epoch: 37 [10000/60000 (17%)]\tLoss: 142.553809\n",
      "Train Epoch: 37 [20000/60000 (33%)]\tLoss: 132.658066\n",
      "Train Epoch: 37 [30000/60000 (50%)]\tLoss: 138.225498\n",
      "Train Epoch: 37 [40000/60000 (67%)]\tLoss: 134.268086\n",
      "Train Epoch: 37 [50000/60000 (83%)]\tLoss: 139.922383\n",
      "====> Epoch: 37 Average loss: 135.6408\n",
      "====> Test set loss: 137.7093\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 129.397900\n",
      "Train Epoch: 38 [10000/60000 (17%)]\tLoss: 128.682695\n",
      "Train Epoch: 38 [20000/60000 (33%)]\tLoss: 130.689014\n",
      "Train Epoch: 38 [30000/60000 (50%)]\tLoss: 133.467588\n",
      "Train Epoch: 38 [40000/60000 (67%)]\tLoss: 137.915732\n",
      "Train Epoch: 38 [50000/60000 (83%)]\tLoss: 134.101963\n",
      "====> Epoch: 38 Average loss: 135.5277\n",
      "====> Test set loss: 137.7922\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 133.426963\n",
      "Train Epoch: 39 [10000/60000 (17%)]\tLoss: 134.972471\n",
      "Train Epoch: 39 [20000/60000 (33%)]\tLoss: 141.030488\n",
      "Train Epoch: 39 [30000/60000 (50%)]\tLoss: 134.528486\n",
      "Train Epoch: 39 [40000/60000 (67%)]\tLoss: 142.112461\n",
      "Train Epoch: 39 [50000/60000 (83%)]\tLoss: 137.004600\n",
      "====> Epoch: 39 Average loss: 135.2835\n",
      "====> Test set loss: 137.8056\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 137.606299\n",
      "Train Epoch: 40 [10000/60000 (17%)]\tLoss: 128.797256\n",
      "Train Epoch: 40 [20000/60000 (33%)]\tLoss: 132.659551\n",
      "Train Epoch: 40 [30000/60000 (50%)]\tLoss: 136.793262\n",
      "Train Epoch: 40 [40000/60000 (67%)]\tLoss: 131.582588\n",
      "Train Epoch: 40 [50000/60000 (83%)]\tLoss: 143.490029\n",
      "====> Epoch: 40 Average loss: 135.2263\n",
      "====> Test set loss: 137.6623\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 131.732598\n",
      "Train Epoch: 41 [10000/60000 (17%)]\tLoss: 131.831943\n",
      "Train Epoch: 41 [20000/60000 (33%)]\tLoss: 139.845723\n",
      "Train Epoch: 41 [30000/60000 (50%)]\tLoss: 138.200537\n",
      "Train Epoch: 41 [40000/60000 (67%)]\tLoss: 133.920488\n",
      "Train Epoch: 41 [50000/60000 (83%)]\tLoss: 134.128428\n",
      "====> Epoch: 41 Average loss: 135.2395\n",
      "====> Test set loss: 138.2206\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 133.228379\n",
      "Train Epoch: 42 [10000/60000 (17%)]\tLoss: 131.278594\n",
      "Train Epoch: 42 [20000/60000 (33%)]\tLoss: 138.851924\n",
      "Train Epoch: 42 [30000/60000 (50%)]\tLoss: 131.885479\n",
      "Train Epoch: 42 [40000/60000 (67%)]\tLoss: 131.933486\n",
      "Train Epoch: 42 [50000/60000 (83%)]\tLoss: 134.124570\n",
      "====> Epoch: 42 Average loss: 135.3573\n",
      "====> Test set loss: 137.9759\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 138.888076\n",
      "Train Epoch: 43 [10000/60000 (17%)]\tLoss: 145.186924\n",
      "Train Epoch: 43 [20000/60000 (33%)]\tLoss: 130.987227\n",
      "Train Epoch: 43 [30000/60000 (50%)]\tLoss: 138.468916\n",
      "Train Epoch: 43 [40000/60000 (67%)]\tLoss: 133.698809\n",
      "Train Epoch: 43 [50000/60000 (83%)]\tLoss: 144.275488\n",
      "====> Epoch: 43 Average loss: 135.2391\n",
      "====> Test set loss: 137.9878\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 142.153350\n",
      "Train Epoch: 44 [10000/60000 (17%)]\tLoss: 139.779932\n",
      "Train Epoch: 44 [20000/60000 (33%)]\tLoss: 128.553955\n",
      "Train Epoch: 44 [30000/60000 (50%)]\tLoss: 137.180137\n",
      "Train Epoch: 44 [40000/60000 (67%)]\tLoss: 133.805498\n",
      "Train Epoch: 44 [50000/60000 (83%)]\tLoss: 137.167266\n",
      "====> Epoch: 44 Average loss: 135.1616\n",
      "====> Test set loss: 137.7449\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 130.973662\n",
      "Train Epoch: 45 [10000/60000 (17%)]\tLoss: 138.944580\n",
      "Train Epoch: 45 [20000/60000 (33%)]\tLoss: 141.119385\n",
      "Train Epoch: 45 [30000/60000 (50%)]\tLoss: 132.419590\n",
      "Train Epoch: 45 [40000/60000 (67%)]\tLoss: 135.065176\n",
      "Train Epoch: 45 [50000/60000 (83%)]\tLoss: 129.672236\n",
      "====> Epoch: 45 Average loss: 134.7451\n",
      "====> Test set loss: 137.6397\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 130.196270\n",
      "Train Epoch: 46 [10000/60000 (17%)]\tLoss: 129.512158\n",
      "Train Epoch: 46 [20000/60000 (33%)]\tLoss: 134.632363\n",
      "Train Epoch: 46 [30000/60000 (50%)]\tLoss: 136.809775\n",
      "Train Epoch: 46 [40000/60000 (67%)]\tLoss: 141.111250\n",
      "Train Epoch: 46 [50000/60000 (83%)]\tLoss: 125.467471\n",
      "====> Epoch: 46 Average loss: 134.6990\n",
      "====> Test set loss: 137.7460\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 133.621182\n",
      "Train Epoch: 47 [10000/60000 (17%)]\tLoss: 132.671865\n",
      "Train Epoch: 47 [20000/60000 (33%)]\tLoss: 138.362197\n",
      "Train Epoch: 47 [30000/60000 (50%)]\tLoss: 136.699824\n",
      "Train Epoch: 47 [40000/60000 (67%)]\tLoss: 132.956826\n",
      "Train Epoch: 47 [50000/60000 (83%)]\tLoss: 139.749229\n",
      "====> Epoch: 47 Average loss: 134.6484\n",
      "====> Test set loss: 137.4552\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 137.434053\n",
      "Train Epoch: 48 [10000/60000 (17%)]\tLoss: 133.426279\n",
      "Train Epoch: 48 [20000/60000 (33%)]\tLoss: 132.249229\n",
      "Train Epoch: 48 [30000/60000 (50%)]\tLoss: 134.934238\n",
      "Train Epoch: 48 [40000/60000 (67%)]\tLoss: 132.262021\n",
      "Train Epoch: 48 [50000/60000 (83%)]\tLoss: 135.939023\n",
      "====> Epoch: 48 Average loss: 134.5722\n",
      "====> Test set loss: 137.8692\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 139.618809\n",
      "Train Epoch: 49 [10000/60000 (17%)]\tLoss: 128.971250\n",
      "Train Epoch: 49 [20000/60000 (33%)]\tLoss: 125.897529\n",
      "Train Epoch: 49 [30000/60000 (50%)]\tLoss: 134.593369\n",
      "Train Epoch: 49 [40000/60000 (67%)]\tLoss: 137.456016\n",
      "Train Epoch: 49 [50000/60000 (83%)]\tLoss: 134.964316\n",
      "====> Epoch: 49 Average loss: 134.6007\n",
      "====> Test set loss: 137.2147\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 135.770020\n",
      "Train Epoch: 50 [10000/60000 (17%)]\tLoss: 135.854092\n",
      "Train Epoch: 50 [20000/60000 (33%)]\tLoss: 138.669141\n",
      "Train Epoch: 50 [30000/60000 (50%)]\tLoss: 133.086973\n",
      "Train Epoch: 50 [40000/60000 (67%)]\tLoss: 131.713047\n",
      "Train Epoch: 50 [50000/60000 (83%)]\tLoss: 131.871279\n",
      "====> Epoch: 50 Average loss: 134.3672\n",
      "====> Test set loss: 137.7115\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(64, 2).cuda()  # 64 组 mu + log_var\n",
    "    sample = vae.decoder(z).cuda()  # output should be (64,784)\n",
    "    \n",
    "    save_image(sample.view(64, 1, 28, 28), './samples/sample_' + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
